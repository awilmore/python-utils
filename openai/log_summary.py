#!/usr/bin/env python3

"""
Summarise the contents of provided log file, allowing for followup questions.
NOTE:
  - OPENAI_API_KEY env var required
"""

import os
import signal
import subprocess
import sys
import time

from openai import OpenAI

###
# GLOBALS
###


SUMMARY_INSTRUCTION = "System: The following text is a snippet of log data generated by an application running in Kubernetes. Each log line is in json format. Please summarise the log data with particular focus on the timeline of events."
MAX_LOG_LENGTH = 32767 - len(SUMMARY_INSTRUCTION) - 1000

###
# MAIN METHOD
###


def main():
    """Main method"""
    client = OpenAI(
        api_key=os.environ.get("OPENAI_API_KEY"),
    )

    # Determine prompt
    instructions = SUMMARY_INSTRUCTION
    print()

    # Load log data
    log_data = fetch_log_data()

    # Create assistant
    assistant = client.beta.assistants.create(model="gpt-4o", name="mx-log-summary-1", instructions=instructions)

    # Create a thread
    thread = client.beta.threads.create()

    # Create initial prompt including log data
    prompt = template_prompt(instructions, log_data)

    # Display initial instruction
    print(f"\033[93m * {instructions}\033[0m")
    print()

    # Create a new message for thread
    client.beta.threads.messages.create(thread_id=thread.id, role="user", content=prompt)

    # Create a new run
    run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant.id)

    # Wait for run to execute
    message = wait_for(client, thread.id, run.id)

    # Present initial summary
    print()
    print_as_gpt(f"Initial summary:\n\n{message}\n")

    # Start interrogation loop
    while True:
        message = input("\033[93m * You: \033[0m")
        print()

        # Check if finished
        if message.strip().lower() == "done":
            break

        # Create a new message for thread
        client.beta.threads.messages.create(thread_id=thread.id, role="user", content=message)

        # Create a new run
        run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant.id)

        # Wait for run to execute
        message = wait_for(client, thread.id, run.id)

        # Display message
        print("\n")
        print_as_gpt(message + "\n")

    # Loop finished. Clean up
    client.beta.assistants.delete(assistant.id)
    print_as_gpt("Okay bye.\n")


def fetch_log_data():
    # Get log path
    log_path = input("\033[93m * Enter full path to log file (file size will be truncated to 30K): \033[0m")
    print()

    # Read log data
    with open(log_path, "r") as f:
        log_data = f.read()

    # Truncate log data if necessary
    if len(log_data) > MAX_LOG_LENGTH:
        log_data = log_data[0:MAX_LOG_LENGTH]

    return log_data


def wait_for(client, thread_id, run_id):
    print("\033[92m( thinking ", end="")

    while True:
        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)

        if run.status in ["completed", "failed"]:
            # Show cost
            tokens = run.usage.total_tokens

            # Finish thinking bubble
            print(f" [{tokens}] )\033[0m", flush=True)

            # Get only latest message
            messages = client.beta.threads.messages.list(thread_id=thread_id, limit=1)
            return messages.data[0].content[0].text.value

        else:
            print(".", end="", flush=True)
            time.sleep(1)


# Template prompt (TODO: use a proper prompt template)
def template_prompt(instruction, text):
    return f"""System: {instruction}.
    Text: {text}
    """


# Print with green
def print_as_gpt(text):
    # Replace newline characters with double-newline characters
    text = text.replace("\r", "\n")

    # Print with green
    print("\033[92m * GPT:\033[0m", text)


# pylint: disable=W0613
def signal_handler(sig, frame):
    """Control signal handler"""
    print(" ")
    sys.exit(0)


# Set up Ctrl-C handler
signal.signal(signal.SIGINT, signal_handler)


###
# MAIN
###

# Invoke main method
if __name__ == "__main__":
    main()
